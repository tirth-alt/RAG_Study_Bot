# CBSE Class 10 AI Tutor Configuration

# Embedding Configuration
embedding:
  model_name: "sentence-transformers/all-MiniLM-L6-v2"
  device: "cpu"  # Use "cuda" if GPU available

# Text Chunking
chunking:
  chunk_size: 1200  # Larger chunks for richer context
  chunk_overlap: 350  # More overlap to preserve connections
  separator: "\n\n"

# ChromaDB Configuration
vectorstore:
  persist_directory: "./vectorstore"
  collection_name: "cbse_class10_textbooks"

# Retrieval Configuration
retrieval:
  top_k: 7  # Balanced: enough coverage, not too much noise/mixing
  score_threshold: 0.5  # Minimum similarity score

# LLM Configuration
llm:
  provider: "ollama"  # Using Ollama (local, free)
  model: "llama3.2"  # Ollama model
  temperature: 0.7  # Lower = more focused, less mixing
  max_tokens: 500  # Allow detailed answers

# Chat Configuration
chat:
  memory_size: 10  # Number of messages to keep in history
  show_sources: true  # Display source chapters/pages

# Subjects
subjects:
  # - english
  - social_science
